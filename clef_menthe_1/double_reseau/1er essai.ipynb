{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import load_img, img_to_array, array_to_img, ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, UpSampling2D, InputLayer\n",
    "from skimage.color import rgb2lab, lab2rgb\n",
    "from IPython.display import display\n",
    "from ipywidgets import interact, IntSlider, Layout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#On charge les images en PIL dans sorties\n",
    "dataset_path = '../../datasets/faces/'\n",
    "images = os.listdir(dataset_path)[:30]\n",
    "sorties = [load_img(dataset_path + image) for image in images]\n",
    "\n",
    "#Possible resize\n",
    "sorties = [image.resize((128, 128)) for image in sorties]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#On transforme en LAB\n",
    "sorties = [rgb2lab(img_to_array(image) / 255) for image in sorties]\n",
    "\n",
    "#On isole les teintes de gris pour entrees\n",
    "#et les teintes de couleurs pour sorties\n",
    "entrees = [image[:, :, 0] for image in sorties]\n",
    "sorties = [image[:, :, 1:] for image in sorties]\n",
    "\n",
    "#On reshape et on renormalise\n",
    "entrees = [image.reshape(image.shape + (1,))/128 for image in entrees]\n",
    "sorties = [image/128 for image in sorties]\n",
    "\n",
    "#On convertit en np array\n",
    "entrees = np.array(entrees)\n",
    "sorties = np.array(sorties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [Sequential(), Sequential()]\n",
    "\n",
    "for model in models:\n",
    "    model.add(InputLayer(input_shape=(None, None, 1)))\n",
    "    model.add(Conv2D(8, (3, 3), activation='relu', padding='same', strides=2))\n",
    "    model.add(Conv2D(8, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(Conv2D(16, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(Conv2D(16, (3, 3), activation='relu', padding='same', strides=2))\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', padding='same', strides=2))\n",
    "    model.add(UpSampling2D((2, 2)))\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(UpSampling2D((2, 2)))\n",
    "    model.add(Conv2D(16, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(UpSampling2D((2, 2)))\n",
    "    model.add(Conv2D(1, (3, 3), activation='tanh', padding='same'))\n",
    "\n",
    "models[0].summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in models:\n",
    "    model.compile(optimizer='rmsprop', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(x, y, epochs, batch_size):\n",
    "    for p in range(epochs):\n",
    "        for i in range(0, len(x), batch_size):\n",
    "            j = i + batch_size\n",
    "            yield (x[i:j], y[i:j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "epochs = 1000\n",
    "\n",
    "for i, model in enumerate(models):\n",
    "    model.fit_generator(generator(entrees, sorties[:, :, :, i:i+1], epochs, batch_size),\n",
    "                        epochs=epochs, verbose = 0,\n",
    "                        steps_per_epoch=len(entrees)/batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_a_img(models, entree):\n",
    "    A = models[0].predict(entree, batch_size=1)\n",
    "    B = models[1].predict(entree, batch_size=1)\n",
    "    AB = np.append(A, B, axis=3)\n",
    "    LAB = np.append(entree, AB, axis=3) * 128\n",
    "    LAB = LAB.reshape(LAB.shape[1:])\n",
    "    return array_to_img(lab2rgb(LAB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_sel(SEL):\n",
    "    display(prediction_a_img(models, entrees[SEL:SEL+1]))\n",
    "\n",
    "    grayscale = np.append(entrees[SEL], np.zeros(entrees[SEL].shape[:2] + (2,)), axis=2) * 128\n",
    "    display(array_to_img(lab2rgb(grayscale)))\n",
    "\n",
    "    colored = np.append(entrees[SEL], sorties[SEL], axis=2) * 128\n",
    "    display(array_to_img(lab2rgb(colored)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interact(print_sel, SEL=IntSlider(min=0,max=len(entrees)-1,step=1,value=0, layout=Layout(width='90%')));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
